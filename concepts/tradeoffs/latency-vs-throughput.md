Latency measures time to complete single operation from request to response typically in milliseconds representing user-experienced delay for individual actions, where lower latency provides better user experience with responsive interfaces, enables real-time interactions, and meets strict SLAs for time-sensitive operations, optimized through techniques like caching frequently accessed data in memory or CDN reducing database trips, geographic distribution placing servers close to users minimizing network distance, connection pooling reusing database connections eliminating establishment overhead, protocol optimization using binary formats like Protocol Buffers instead of JSON, parallel processing executing independent tasks concurrently, and reducing synchronous dependencies through async patterns, measured using percentiles (p50, p95, p99) rather than averages to capture tail latencies affecting real users, while Throughput measures operations processed per unit time (requests/second, transactions/minute) representing system capacity to handle load, where higher throughput supports more concurrent users, processes larger data volumes, and maximizes resource utilization, optimized through batching multiple operations together amortizing overhead, pipelining overlapping operations to hide latency, increasing parallelism with more threads or workers, asynchronous processing decoupling slow operations, compression reducing data transfer size, and efficient algorithms minimizing computational complexity, with fundamental tension where optimizing for one often degrades the other through trade-offs like batching improving throughput by processing multiple requests together but increasing latency as requests wait for batch to fill, caching reducing latency but consuming memory that could handle more requests, parallel processing improving throughput but introducing coordination overhead increasing individual request latency, and compression trading CPU time (increasing latency) for reduced network transfer (improving throughput), illustrated by scenarios like database writes where immediate acknowledgment (sync replication to all replicas) provides low latency guarantees but limits throughput, while batched async replication increases throughput but raises latency, and network protocols where TCP ensures reliable delivery with acknowledgments (better for throughput of large transfers) while UDP skips acknowledgments (better for low latency of small messages), with Little's Law formalizing relationship as Throughput = Concurrency / Latency showing that for fixed latency, throughput increases with more concurrent requests, and for fixed concurrency, reducing latency increases throughput, where Latency-sensitive applications include trading systems where microseconds matter, online gaming requiring responsive controls, voice/video calls needing real-time communication, user-facing web applications where delays frustrate users, and IoT device control with safety implications, while Throughput-oriented applications include batch processing ETL jobs maximizing data volume processed, log aggregation handling billions of events, video encoding processing large files, data warehousing analytics queries, and background jobs where individual task latency less important than total completion time, with hybrid requirements like web servers needing low latency for individual requests while maintaining high throughput for concurrent users, implemented through techniques like request prioritization handling latency-sensitive requests in fast path while batching throughput-oriented work, auto-scaling adding capacity for throughput while keeping individual instances responsive, and tiered storage using fast SSD for latency-critical data while slow HDD for throughput-heavy archives, measured and monitored through SLI (Service Level Indicators) defining targets like p99 latency under 100ms AND throughput over 10000 req/sec, where optimization depends on use case requirements, user expectations, cost constraints, and system bottlenecks with modern distributed systems often requiring balancing both through careful architecture and operational tuning.
