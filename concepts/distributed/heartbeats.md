Heartbeats are periodic signals sent between distributed system nodes to detect failures and maintain membership information, where nodes send small messages at regular intervals (typically 1-10 seconds) to coordinator or peers, with failure detection when heartbeat missing for threshold period indicating node crash or network partition, implemented through Push Model where monitored nodes actively send heartbeats to monitor reducing detection latency but consuming bandwidth proportional to number of nodes, Pull Model where monitor periodically polls nodes for health status simplifying node implementation but increasing detection latency, or Hybrid approaches combining both for balance, using adaptive timeout periods accounting for network variability with phi-accrual failure detector calculating suspicion level based on heartbeat arrival patterns rather than fixed timeout providing gradual failure detection and reducing false positives from temporary slowdowns, commonly implemented in coordination services like ZooKeeper using session heartbeats where clients must heartbeat within session timeout or lose ephemeral nodes, distributed databases maintaining cluster membership with gossip protocols spreading heartbeat information, load balancers performing health checks on backend servers removing unresponsive instances from rotation, and microservices using service mesh sidecar proxies for health monitoring and circuit breaking, with challenges including Network Partitions where nodes alive but unreachable requiring partition detection and quorum-based decisions, False Positives from GC pauses or temporary network delays requiring tuning timeout vs detection speed trade-off, Clock Skew in distributed systems using monotonic clocks and relative timeouts instead of absolute timestamps, Scalability with full-mesh heartbeats growing O(nÂ²) requiring hierarchical approaches or gossip protocols spreading information with O(log n) messages, and Overhead optimization by piggybacking heartbeats on existing traffic or adjusting frequency based on system load, typically combined with failure recovery mechanisms like leader election when coordinator fails, automated failover promoting standby to primary, and graceful degradation removing failed nodes from service but maintaining system operation.
